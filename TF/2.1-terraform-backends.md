# Terraform Backends (S3 + DynamoDB)

## Why use a remote backend
Local state is convenient for single-developer experiments but has real risks in team or persistent projects:
- State lives on one machine — lost or corrupted local files can make infrastructure unrecoverable.
- No locking — concurrent applies can corrupt state or cause drift.
- Hard to share — other team members can't reliably consume outputs or collaborate.
A remote backend (S3 for state + DynamoDB for locks) solves these issues: central storage, locking, encryption, and easier CI integration.

## Overview
This lab shows how to:
- Create an S3 bucket and DynamoDB table for Terraform state and locking
- Configure Terraform to use the S3 backend
- Initialize and migrate existing local state to S3
- Verify remote state and show how to consume outputs from it

Apply the changes in the `tf-lab3` directory.

## Prerequisites
- AWS CLI configured with an IAM user that can create S3 buckets and DynamoDB tables
- Terraform installed
- A globally unique S3 bucket name

Tip: You can perform the resource creation via the AWS Console or CloudShell if you prefer a GUI or don't have AWS CLI locally.

## 1) Create the backend resources
Run (Bash / CloudShell):

**IMPORTANT** - Update the bucket name to a unique name, bucket names MUST be unique per aws region.

```bash
BUCKET="your-unique-bucket-name"
REGION="us-west-1"

# create S3 bucket (replace region if needed)
aws s3api create-bucket --bucket "$BUCKET" --region "$REGION" --create-bucket-configuration LocationConstraint="$REGION"

# create DynamoDB table for state locking
aws dynamodb create-table \
  --table-name terraform-state-lock \
  --attribute-definitions AttributeName=LockID,AttributeType=S \
  --key-schema AttributeName=LockID,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST \
  --region "$REGION"
```

## 2) Add backend configuration
Create a `backend.tf` in `tf-lab3` with your bucket and table names:

```hcl
terraform {
  backend "s3" {
    bucket         = "your-unique-bucket-name" // UPDATE
    key            = "tf-lab3/terraform.tfstate" 
    region         = "us-west-1"
    dynamodb_table = "terraform-state-lock"
    encrypt        = true
  }
}
```

Do not put AWS credentials in this file; use the AWS CLI credential chain or environment variables.

## 3) Initialize and migrate state
From the `tf-lab3` directory run:

```bash
terraform init
```

When migrating from local state, Terraform will prompt to copy local state to the remote backend — confirm to migrate. If changing backend settings later, use:

```bash
terraform init -reconfigure
```

Verify remote state:

```bash
terraform state pull    # prints remote state JSON
```

## 4) Test with apply and destroy

Now that your state is stored remotely in S3, test the backend:

```bash
terraform apply
```

Type `yes` to confirm. Your state changes will be saved to S3 and the DynamoDB table will handle locking during the operation.

Now destroy the resources:

```bash
terraform destroy
```

Type `yes` to confirm.

**Important:** Your Terraform state is now stored securely in the cloud:
- **Centralized** - Multiple team members can access the same state
- **Locked** - DynamoDB prevents concurrent modifications
- **Safe** - No local state files that can be lost or corrupted

## Notes and cautions
- DynamoDB locking prevents concurrent writes — recommended for teams.
- S3 objects can expose sensitive state; enable encryption and secure bucket IAM.
- Avoid committing backend.tf with environment-specific values to shared repos; consider partial backend configuration or CI-provided backend settings.
- If you need to stop using a backend, follow `terraform init -reconfigure -backend=false` and manage state carefully.

## Cleanup
If you created the resources for the lab and want to remove them:

```bash
# optional: back up state first
terraform state pull > state-backup.json

# remove S3 bucket and objects
aws s3 rb s3://"$BUCKET" --force

# delete DynamoDB table
aws dynamodb delete-table --table-name terraform-state-lock --region us-west-1
```

Warning: deleting the bucket removes the state file. Back up before deleting if you plan to reuse the infrastructure.