# Lab 4.1: Multi-Environment Zero-Downtime Deployments

## Overview

You've built a dev environment. Now create QA and production environments and practice promoting code through them.

**Your Mission:**
- Create QA and Production environments
- Deploy updates through dev â†’ QA â†’ prod pipeline
- Observe zero-downtime deployments
- Practice rollback procedures

---

## Prerequisites

- Completed Labs 2.1, 2.2, and 2.3
- Dev environment running

---

## Part 1: Create QA Environment (30 minutes)

### Your Task

Create a separate QA environment using the same Terraform code as dev.

**Hints:**
- Use a separate `.tfvars` file (e.g., `qa.tfvars`)
- Set `environment = "qa"`
- Deploy with: `terraform apply -var-file="qa.tfvars"`

**Requirements:**
- Completely isolated from dev (own VPC, ALB, ASG, etc.)
- Uses same AMI as dev
- Can be smaller (2 instances instead of 4)

**Think About:**
- How do you prevent resource name conflicts?
- Should QA always use `most_recent` AMI?
- What makes QA different from dev?
- How do you keep Terraform state separate for each environment? (Hint: look into Terraform workspaces)

**Success:** QA environment accessible at its own ALB URL

---

## Part 2: Create Production Environment (30 minutes)

### Your Task

Create production environment with **controlled deployments**.

**Requirements:**
- Higher capacity than dev/QA (more instances)
- Uses same Terraform code as dev/QA
- Requires manual promotion from QA

**Think About:**
- Production should only deploy tested AMIs, not every new build
- How do you control which AMI production uses?
- What's your promotion workflow from QA to prod?

**Success:** Production environment exists and is accessible

---

## Part 3: Deploy Through the Pipeline (45 minutes)

### Your Task

Update your application and deploy it through all environments.

**Workflow:**

**1. Update Application**
- Change your FastAPI code (version bump, new message, new endpoint - your choice)
- Push to GitHub â†’ Docker image builds

**2. Deploy to Dev**
- Trigger Packer AMI build with `environment=dev`
- Run `terraform apply -var-file="dev.tfvars"`
- Test the changes

**3. Deploy to QA**
- Trigger Packer AMI build with `environment=qa`
- Run `terraform apply -var-file="qa.tfvars"`
- Test thoroughly in QA
- Verify zero-downtime deployment

**4. Promote to Production**
- Trigger Packer AMI build with `environment=prod`
- Run `terraform apply -var-file="prod.tfvars"`
- Monitor the rollout

**Monitor Your Deployments:**
```bash
# Watch instance refresh
watch -n 5 "aws autoscaling describe-instance-refreshes \
  --auto-scaling-group-name <asg-name> \
  --query 'InstanceRefreshes[0]' --output table"

# Test continuously
watch -n 2 "curl -s <alb-url>"
```

**Observe:**
- Mixed responses during deployment (old + new versions)
- No errors or downtime
- Gradual instance replacement

**Questions to Answer:**
- How long did each environment take to deploy?
- Did you see zero downtime?
- What testing would you do in QA before prod?

---

## Part 4: Bonus Challenges (Optional)

### Bonus 1: Semantic Versioning

Tag your AMIs with semantic versions instead of timestamps.

**Hints:**
- Use git tags for your application (`v1.0.0`, `v2.0.0`)
- Pass version to Packer as a variable
- Name AMI: `fastapi-golden-ami-v2.0.0`
- Easier to track and rollback!

### Bonus 2: Perform a Rollback

Simulate a broken deployment and roll back.

**Scenario:**
1. Deploy a "broken" version to production
2. Detect the issue (simulate with failed health checks)
3. Roll back to previous working AMI

**Rollback Method:**

The cleanest way is to delete the broken AMI and re-run Terraform:

```bash
# 1. Find the broken AMI (adjust filter to match your production tag)
aws ec2 describe-images --owners self \
  --filters "Name=name,Values=fastapi-golden-ami-prod*" \
  --query 'Images[*].[ImageId,Name,CreationDate]' --output table

# 2. Delete the broken AMI (latest one)
aws ec2 deregister-image --image-id ami-xxxxx

# 3. Re-run Terraform (no code changes needed!)
terraform apply -var-file="prod.tfvars"
```

**Why this works:**
- Terraform's `most_recent = true` now finds the previous AMI
- No code changes = no drift, no forgetting hardcoded IDs
- Pipeline stays simple and idempotent
- Same workflow works every time


### Bonus 3: Pre-Build Smoke Tests

Add a safety check: Before building a QA or Prod AMI, verify the previous environment is healthy.

**Challenge:**
Modify your GitHub Actions workflow to include a smoke test before triggering Packer.

**Approach:**
- If building QA AMI â†’ First verify Dev is healthy
- If building Prod AMI â†’ First verify QA is healthy

**Hints:**
- Use AWS CLI to get the ALB DNS name for the previous environment
- Use `curl` to test the health endpoint
- Only trigger Packer if the smoke test passes
- Combine with conditional logic: `if [ "$ENV" == "qa" ] || [ "$ENV" == "prod" ]; then ...`

**Why this matters:**
Prevents building broken AMIs from broken environments. If Dev is down, don't build QA!

---

## Part 4: Discussion Questions

### Environment Strategy

1. Why shouldn't production auto-deploy latest code?
2. How do you balance speed vs. safety in deployments?
3. What happens if QA and dev use different AMIs?

### Testing Strategy

**Testing at Each Stage:**

**Dev Testing (Automated):**
- Smoke tests: `curl <alb-url>/health` - is it responding?
- Unit tests: Does the code logic work?

**QA Testing (Automated + Manual):**
- Integration tests: Does the app work with other services?
  - Example: If your app writes to S3, test the upload/download
  - Example: If your app uses RDS, test database queries
- Regression tests: Did we break existing features?
- Security scans: Any vulnerabilities?

**Production Promotion (Manual Approval):**
- All QA tests must pass
- Load testing results reviewed
- Manual sign-off required

**Real Integration Test Example:**
If your FastAPI app uses S3 for file storage:
```bash
# Test S3 integration in QA
curl -X POST <qa-alb-url>/upload -F "file=@test.txt"
curl <qa-alb-url>/files/test.txt  # Should return file
```
Only promote to prod if S3 integration works in QA!

**Note:** In real pipelines, these tests run automatically in GitHub Actions/Jenkins after each deployment. The pipeline only promotes to the next environment if all tests pass.

**Real-world considerations:**
- How long should QA testing take?
- Who approves production deployments?
- What metrics indicate a successful deployment?

### Failure Scenarios

1. What if an instance fails health checks during refresh?
2. How quickly can you rollback a bad deployment?
3. Should you ever skip QA and deploy directly to prod?


---

## Success Criteria

- [ ] Created QA environment (separate from dev)
- [ ] Created production environment (controlled deployments)
- [ ] Updated application code
- [ ] Deployed update through dev â†’ QA â†’ prod
- [ ] Observed zero-downtime rolling deployments
- [ ] Production uses specific AMI (not auto-latest)
- [ ] Understand promotion workflow
- [ ] Can explain rollback procedure

**Bonus:**
- [ ] Implemented semantic versioning for AMIs
- [ ] Successfully performed a rollback
- [ ] Designed an automated promotion strategy

---

## Key Takeaways

**Multi-Environment Pipeline:**
- Dev: Fast iteration, latest code
- QA: Stable testing, controlled updates
- Production: Manual promotion, approved releases only

**Deployment Best Practices:**
- Immutable infrastructure (AMIs, not in-place updates)
- Zero-downtime rolling deployments
- Easy rollbacks (just point to old AMI)
- Testing at each stage before promotion

**Real-World Application:**
This is how companies like Netflix, Airbnb, and Stripe deploy:
- Automated dev/QA deployments
- Manual approval for production
- Gradual rollouts with monitoring
- Quick rollback capability

---

## Cleanup

**Important:** Don't forget to tear down all your environments to avoid AWS charges!

```bash
# Destroy each environment
# (Switch workspaces if you used them, or run from appropriate directory)
terraform destroy -var-file="dev.tfvars"
terraform destroy -var-file="qa.tfvars"
terraform destroy -var-file="prod.tfvars"

# Optional: Clean up old AMIs
aws ec2 describe-images --owners self --query 'Images[*].[ImageId,Name,CreationDate]' --output table
aws ec2 deregister-image --image-id ami-xxxxx
```

---

**Congratulations!** You've built a complete multi-environment deployment pipeline! ðŸŽ‰
